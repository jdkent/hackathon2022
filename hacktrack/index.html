<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1,minimum-scale=1.0,maximum-scale=1.0,user-scalable=no"> <meta name="author" content="OHBM Open-science Special Interest Group"> <meta name="description" content="OHBM Brainhack June 16-18th, 2022. Organized by the OHBM Open Science SIG."> <meta name="keywords" content="brainhack, neuroscience, AI"> <!-- <meta name="google-site-verification" content="" /> <link rel="canonical" href="https://ohbm.github.io/hackathon2022"> --> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:site" content="@OhbmOpen"> <meta name="twitter:title" content="HackTrack"> <meta name="twitter:description" content="OHBM Brainhack June 16-18th, 2022. Organized by the OHBM Open Science SIG."> <meta name="twitter:image:src" content="https://ohbm.github.io/hackathon2022/hackathon2022"> <meta property="og:title" content="HackTrack" /> <meta property="og:site_name" content="OHBM BrainHack 2022" /> <meta property="og:type" content="website" /> <meta property="og:url" content="https://ohbm.github.io/hackathon2022" /> <meta property="og:image" content="https://ohbm.github.io/hackathon2022/hackathon2022" /> <meta property="og:image:width" content="700" /> <meta property="og:image:height" content="350" /> <meta property="og:description" content="OHBM Brainhack June 16-18th, 2022. Organized by the OHBM Open Science SIG." /> <title>HackTrack &bull; OHBM BrainHack 2022</title> <link rel="shortcut icon" href="/hackathon2022/img/favicons/favicon.ico"> <link rel="apple-touch-icon" sizes="152x152" href="/hackathon2022/img/favicons/apple-icon-152x152.png"> <link rel="apple-touch-icon" sizes="144x144" href="/hackathon2022/img/favicons/apple-icon-144x144.png"> <link rel="apple-touch-icon" sizes="120x120" href="/hackathon2022/img/favicons/apple-icon-120x120.png"> <link rel="apple-touch-icon" sizes="114x114" href="/hackathon2022/img/favicons/apple-icon-114x114.png"> <link rel="apple-touch-icon" sizes="76x76" href="/hackathon2022/img/favicons/apple-icon-76x76.png"> <link rel="apple-touch-icon" sizes="72x72" href="/hackathon2022/img/favicons/apple-icon-72x72.png"> <link rel="apple-touch-icon" sizes="60x60" href="/hackathon2022/img/favicons/apple-icon-60x60.png"> <link rel="apple-touch-icon" sizes="57x57" href="/hackathon2022/img/favicons/apple-icon-57x57.png"> <link rel="icon" type="image/png" href="/hackathon2022/img/favicons/favicon-96x96.png"> <link rel="icon" type="image/png" href="/hackathon2022/img/favicons/favicon-32x32.png"> <link rel="icon" type="image/png" href="/hackathon2022/img/favicons/favicon-16x16.png"> <meta name="msapplication-TileColor" content="#2b5797"> <meta name="msapplication-TileImage" content="/hackathon2022/img/favicons/mstile-144x144.png"> <meta name="msapplication-config" content="/hackathon2022/img/favicons/browserconfig.xml"> <meta name="theme-color" content="#2b5797"> <link href="/hackathon2022/css/main.css" rel="stylesheet"> <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries --> <!-- WARNING: Respond.js doesn't work if you view the page via file:// --> <!--[if lt IE 9]> <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script> <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script> <![endif]--> </head> <body> <div id="preloader" class="preloader"> <div class="loader-gplus"></div> </div> <div id="st-container" class="st-container disable-scrolling"> <div class="st-pusher"> <div class="st-content"> <!-- Begin Top Section --> <section id="top-section" class="top-section image-section enable-overlay" style="background-image: url('/hackathon2022/img/sections-background/25900655562_27549efb87_o.jpg');"> <div class="overlay gradient-overlay"></div> <header id="top-header" class="top-header"> <div class="overlay white-solid"></div> <svg id="menu-trigger" class="menu-trigger icon icon-menu visible-xs visible-sm visible-md" viewBox="0 0 32 32"> <use xlink:href="/hackathon2022/img/sprites/sprites.svg#icon-menu"></use> </svg> <a href="/hackathon2022/" id="logo-header" class="logo-header"> <div class="logo logo-light"></div> </a> <nav class="st-menu st-effect" id="menu"> <div class="logo-navbar logo logo-dark visible-xs visible-sm"></div> <ul> <li> <a class="" href=" /hackathon2022/schedule " >Schedule</a> </li> <li> <a class="" href=" /hackathon2022/hacktrack " >HackTrack</a> </li> <li> <a class="" href=" /hackathon2022/traintrack/ " >TrainTrack Corner</a> </li> <li> <a class="" href=" /hackathon2022/buddy-system/ " >Buddy System</a> </li> </ul> <ul id="bottom-navlinks" class="bottom-navlinks visible-xs visible-sm"> </ul> </nav> </header> <div class="content-wrapper"> <div class="jumbotron text-left"> <div class="animated hiding" data-animation="fadeInLeft" data-delay="500"> <h1>HackTrack</h1> </div> </div> </div> </section> <!-- End Top Section --> <!-- About Hackathon Section --> <section id="about-hackathon" class="about-hackathon"> <div class="content-wrapper"> <div class="col-md-8 col-md-offset-2"> <h3>HackTrack projects</h3> <div style="text-align: justify;"> <h6> <br>The <b>HackTrack</b> is the official <b>fun side</b> of a <b>Brainhack</b> event, where people can work together on projects. What projects? Any kind! From <a href="https://github.com/ohbm/hackathon2020/issues/124" target="_blank">exploding brains</a> to <a href="https://github.com/ohbm/hackathon2020/issues/166" target="_blank">resource gathering</a> and <a href="https://github.com/ohbm/hackathon2020/issues/156" target="_blank">data sharing</a>!<br><br> Would you like to propose a project? Just open <a href="https://github.com/ohbm/hackathon2022/issues/new/choose" target="_blank"> an issue on our GitHub repository</a> and fill the template, we will be in touch to help you get going! But be sure to <a href="https://www.humanbrainmapping.org/i4a/pages/index.cfm?pageid=4073" target="_blank"> register</a> first!<br><br> Do you plan to focus on visualization? Are you getting images so weird that they are kind of beautiful? Consider participating in the <em>Beautiful Mistake</em> category of the <a href="https://ohbm-brainart.github.io" target="_blank">BrainArt SIG</a> competition! You can find the submission form <a href="https://docs.google.com/forms/d/e/1FAIpQLSdkfoq-VF_Aw27MD1whBAZCFl6BHldOpOAQ2GWSXFng7fD3Vw/viewform" target="_blank">here</a>.<br><br> </h6> </div> <div class="hackathon-row float-left col-md-12"> <div class="hackathon-img-wrapper animated hiding" data-animation="fadeInLeft" data-delay="0"> <img class="img-responsive" src="https://neuosc.com/wp-content/uploads/2022/03/Flux-Logo-1-370x153.png" alt="Hackathon"> </div> <div class="hackathon-details animated hiding" data-animation="fadeInRight" data-delay="0"> <h4><a href="https://github.com/Neuronal-Oscillations/FLUX">FLUX: A pipeline for MEG analysis and beyond</a></h4> <h6> Hubs: Glasgow, Europe / Middle East / Africa </h6> <h5>PROJECT DESCRIPTION</h5> <p><p><a href="https://neuosc.com/flux/">FLUX </a> is a pipeline for analysing magnetoencephalography (MEG) data. By making the analyses steps and setting explicit, it aims to facilitate open science with the larger goal of improving the replicability of MEG research. So far, the FLUX pipeline has been developed for MNE-Python and FieldTrip with a focus on the MEGIN/Elekta system. The goal of this Brainhack project is to make the FLUX pipeline more flexible by making it fully BIDS compatible, as well as expanding its application to other systems, for instance CTF, optically pumped magnetometer (OPM) and electroencephalography (EEG).</p> </p> <h5>SKILLS</h5> <p><p>This is an ongoing project and there are many ways in which you could contribute; from helping to improve the documentation to developing new functionalities, all kinds of contributions are welcome. Any of the following skills will be very helpful:</p> <ul> <li>experience with MEG or any other neurophysiological method</li> <li>basic Python/MATLAB knowledge</li> <li>familiarity with BIDS</li> <li>good writing skills</li> <li>being enthusiastic about Neuroscience!</li> </ul> </p> </div> </div> <div class="hackathon-row float-left col-md-12"> <div class="hackathon-img-wrapper animated hiding" data-animation="fadeInLeft" data-delay="0"> <img class="img-responsive" src="https://nipy.org/nibabel/_static/reggie.png" alt="Hackathon"> </div> <div class="hackathon-details animated hiding" data-animation="fadeInRight" data-delay="0"> <h4><a href="https://github.com/nipy/nibabel/">Type hints for NiBabel</a></h4> <h6> Hubs: Glasgow </h6> <h5>PROJECT DESCRIPTION</h5> <p><p>Python has support for <a href="https://docs.python.org/3/library/typing.html">type annotations</a> to help developers code more effectively by catching bugs via static analysis or making auto-complete suggestions. The more libraries that annotate their code with useful type hints, the more effective this assistance becomes. The goal of this project is to annotate NiBabel to ease the development process for neuroimaging in Python and improve the reliability of code built on top of NiBabel. We will use <a href="http://mypy-lang.org/">mypy</a> for static analysis and test out type hinting in VScode.</p> </p> <h5>SKILLS</h5> <p><p>Minimum</p> <ul> <li>Some experience with Python and numpy</li> </ul> <p>Ideal</p> <ul> <li>Familiarity with some NiBabel APIs</li> <li>Experience with the <a href="https://docs.python.org/3/library/typing.html">typing</a> and <a href="https://numpy.org/devdocs/reference/typing.html">numpy.typing</a></li> </ul> </p> </div> </div> <div class="hackathon-row float-left col-md-12"> <div class="hackathon-img-wrapper animated hiding" data-animation="fadeInLeft" data-delay="0"> <img class="img-responsive" src="" alt="Hackathon"> </div> <div class="hackathon-details animated hiding" data-animation="fadeInRight" data-delay="0"> <h4><a href="https://github.com/neuronets/">Nobrainer toolkit and model zoo for deep learning in neuroimaging</a></h4> <h6> Hubs: Glasgow </h6> <h5>PROJECT DESCRIPTION</h5> <p><p>The goals of this hackathon are to improve usability of both the nobrainer library and the nobrainer model zoo.</p> </p> <h5>SKILLS</h5> <p><ul> <li>Python</li> </ul> <p>Optional:</p> <ul> <li>Tensorflow</li> <li>Docker/Singularity</li> </ul> </p> </div> </div> <div class="hackathon-row float-left col-md-12"> <div class="hackathon-img-wrapper animated hiding" data-animation="fadeInLeft" data-delay="0"> <img class="img-responsive" src="https://uvaauas.figshare.com/ndownloader/files/27251792/preview/27251792/preview.jpg" alt="Hackathon"> </div> <div class="hackathon-details animated hiding" data-animation="fadeInRight" data-delay="0"> <h4><a href="https://github.com/piloubazin/AHEAD-brains">Exploring the AHEAD brains together</a></h4> <h6> Hubs: Glasgow </h6> <h5>PROJECT DESCRIPTION</h5> <p><p>We recently made available a post-mortem data set including quantitative MRI and microscopy reconstructed in 3D at 200µm (see <a href="https://doi.org/10.1126/sciadv.abj7892">this article</a> for details). The data set is openly accessible on FigShare already, but we would like to do more to help integrate it in other open science platforms to promote collaborative exploration of the data.</p> <p>Goals for the Brainhack:</p> <ul> <li>set up a version of the data set that fits into <a href="https://brainbox.pasteur.fr/">Brainbox</a></li> <li>check how the data is handled by various visualization tools, make recommendations</li> <li>import initial parcellations from automated tools (nighres so far, but others could be run) into the visualizations</li> <li>manually annotate errors, artifacts, inconsistencies</li> <li>delineate new structures collaboratively</li> </ul> </p> <h5>SKILLS</h5> <p><ul> <li>enthusiasm for detail neuroanatomy</li> <li>dealing with data (re)formatting, header manipulation</li> <li>experience with various brain visualization tools</li> <li>ideas to increase collaboration in neuroanatomical atlasing</li> </ul> </p> </div> </div> <div class="hackathon-row float-left col-md-12"> <div class="hackathon-img-wrapper animated hiding" data-animation="fadeInLeft" data-delay="0"> <img class="img-responsive" src="https://raw.githubusercontent.com/nilearn/nilearn/main/doc/logos/nilearn-logo.png" alt="Hackathon"> </div> <div class="hackathon-details animated hiding" data-animation="fadeInRight" data-delay="0"> <h4><a href="https://github.com/nilearn/nilearn">Nilearn: Statistics for Neuroimaging in Python</a></h4> <h6> Hubs: Europe / Middle East / Africa, Glasgow </h6> <h5>PROJECT DESCRIPTION</h5> <p><p>Nilearn is an open-source Python package for fast and easy analysis and visualization of brain images. It provides statistical and machine-learning tools, with instructive documentation and a friendly community. It includes applications such as multi-voxel pattern analysis (MVPA), decoding, predictive modelling, functional connectivity, and brain parcellations. Moreover, in recent years, Nilearn has expanded to include Generalized Linear Models (GLMs) to analyse functional MRI data. For the Brainhack, we aim to get feedback from the community about some of the highlights of the latest release. These include:</p> <ul> <li>A new module <a href="https://nilearn.github.io/stable/modules/reference.html#module-nilearn.interfaces">nilearn.interfaces</a> to implement loading and saving utilities with various interfaces</li> <li>Ability to provide <a href="https://nilearn.github.io/stable/auto_examples/04_glm_first_level/plot_hrf.html#sphx-glr-auto-examples-04-glm-first-level-plot-hrf-py">custom hemodynamic response function (HRF)</a> for dealing with non human primate data in GLM analysis</li> <li><a href="https://nilearn.github.io/stable/auto_examples/01_plotting/plot_3d_map_to_surface_projection.html#interactive-plotting-with-plotly">Interactive surface plotting</a> using Plotly engine</li> <li>Improved <a href="https://nilearn.github.io/stable/development.html">contributing documentation</a></li> </ul> <p>Finally, we are always looking to get feedback on our <a href="https://nilearn.github.io/stable/index.html">documentation</a> and to onboard new contributors.</p> </p> <h5>SKILLS</h5> <p><p>We welcome all contributions from various skill sets and levels. This can include opening discussions around improvements to the <a href="https://nilearn.github.io/stable/index.html">documenation</a> and/or <a href="https://github.com/nilearn/nilearn">code base</a>, answering or commenting on questions or <a href="https://github.com/nilearn/nilearn/issues">issues raised on github</a> and <a href="https://neurostars.org/tag/nilearn">neurostars</a>, reviewing <a href="https://github.com/nilearn/nilearn/pulls">pull requests</a>, and <a href="https://nilearn.github.io/stable/development.html#how-to-contribute-to-nilearn">contributing code</a>.</p> </p> </div> </div> <div class="hackathon-row float-left col-md-12"> <div class="hackathon-img-wrapper animated hiding" data-animation="fadeInLeft" data-delay="0"> <img class="img-responsive" src="https://user-images.githubusercontent.com/5311102/166160831-a81f55c3-c131-4e12-ab1f-e3f46593c9e5.png" alt="Hackathon"> </div> <div class="hackathon-details animated hiding" data-animation="fadeInRight" data-delay="0"> <h4><a href="https://github.com/danielemarinazzo/HOI">Higher order informational interactions in neuroimaging</a></h4> <h6> Hubs: Europe / Middle East / Africa </h6> <h5>PROJECT DESCRIPTION</h5> <p><p><a href="https://www.nature.com/articles/s41593-022-01070-0">Higher order interactions are being increasingly used and applied to neuroimaging data</a> To date there isn’t a freely available python toolbox with proper input/output suitable for neuroimaging data. We have a pretty much optimized <a href="https://github.com/danielemarinazzo/HOI">matlab code</a>, and <a href="https://github.com/PranavMahajan25/HOI_toolbox">a functioning, yet not optimized python one</a> by @PranavMahajan25 (with <a href="https://github.com/brainets/hoi_bhk/tree/main/etienne">some improvements</a> by @EtienneCmb). The goal(s) would be:</p> <ul> <li>improve the python implementation, adding statistical tests which are absent at the moment, adapting them from the matlab repository</li> <li>improve speed</li> <li>add input/output from BIDS processed data (MNE/NiLearn)</li> <li>explore solutions for plotting the data (<a href="https://github.com/renzocom/hyperplot">some attempts</a> by @renzocom) <a href="https://discord.gg/VUrQGnF8bc">Discord server for the project</a></li> </ul> </p> <h5>SKILLS</h5> <p><p>Python Matlab would help for the translation, but we can assist Some notions of statistics/probability theory could also help, but not necessary</p> </p> </div> </div> <div class="hackathon-row float-left col-md-12"> <div class="hackathon-img-wrapper animated hiding" data-animation="fadeInLeft" data-delay="0"> <img class="img-responsive" src="https://ohbm-environment.org/wp-content/uploads/2021/12/logo_long-1.png" alt="Hackathon"> </div> <div class="hackathon-details animated hiding" data-animation="fadeInRight" data-delay="0"> <h4><a href="https://github.com/neurodatascience/watts_up_compute">watts_up_compute</a></h4> <h6> Hubs: Glasgow </h6> <h5>PROJECT DESCRIPTION</h5> <p><p>Integration of compute-tracker tools into neuroimaging pipelines to estimate carbon footprint of image processing. This is an ongoing project by the Sustainability and Environmental Action group (<a href="https://ohbm-environment.org/">SEA-SIG</a>) at the Organisation for Human Brain Mapping (OHBM). In this project we aim at better understanding the environmental costs of commonly used research pipelines and develop tools to help reduce them. Recently there have been several projects that track cpu/gpu “power draws” incurred during a compute task. These statistics can then be translated into carbon-footprint based on your location and time of processing.</p> <p>Available trackers</p> <ol> <li><a href="https://github.com/mlco2/codecarbon">CodeCarbon</a></li> <li><a href="https://github.com/lfwa/carbontracker">CarbonTracker</a></li> <li><a href="https://github.com/Breakend/experiment-impact-tracker">EIT</a></li> </ol> <p>Available trackers</p> <ol> <li>General purpose <a href="https://github.com/neurodatascience/watts_up_compute">wrapper</a> with CodeCarbon and EIT</li> <li>fMRIPrep <a href="https://github.com/nikhil153/fmriprep/blob/carbon-trackers/singularity/carbon_trackers_readme.md">integration</a> with CodeCarbon</li> </ol> <p>Available trackers</p> <ol> <li>Test fMRIPrep integration on multiple hardware</li> <li>Integrate trackers into other neuroimaging pipelines e.g. FSL, SPM etc.</li> </ol> </p> <h5>SKILLS</h5> <p><p>You don’t need to be familiar with all of these, just any subset of these would do!</p> <p>Programming languages</p> <ul> <li>Python</li> <li>Bash</li> <li>Matlab</li> </ul> <p>Neuro-software specific skills</p> <ul> <li>FreeSurfer</li> <li>fMRIPrep</li> <li>NiPype</li> <li>SPM</li> <li>FSL</li> </ul> <p>Data standards</p> <ul> <li>Brain Imaging Data Structure (BIDS)</li> </ul> <p>Git skills</p> <ul> <li>Git - 2: comfortable working with branches and can do a pull request on another repository</li> </ul> </p> </div> </div> <div class="hackathon-row float-left col-md-12"> <div class="hackathon-img-wrapper animated hiding" data-animation="fadeInLeft" data-delay="0"> <img class="img-responsive" src="https://user-images.githubusercontent.com/29738718/170998973-86081990-33b6-45c2-9d77-21e68aea9053.png" alt="Hackathon"> </div> <div class="hackathon-details animated hiding" data-animation="fadeInRight" data-delay="0"> <h4><a href="https://github.com/datalad/datalad-dataverse">DataLad-Dataverse integration</a></h4> <h6> Hubs: Glasgow, Europe / Middle East / Africa </h6> <h5>PROJECT DESCRIPTION</h5> <p><p><a href="https://dataverse.org">Dataverse</a> is open source research data repository software that is deployed all over the world in data or metadata repositories, so called Dataverse collections. It supports sharing, preserving, citing, exploring, and analyzing research data with descriptive metadata, and thus contributes greatly to open, reproducible, and FAIR science. <a href="https://www.datalad.org">DataLad</a>, on the other hand, is a data management and data publication tool build on <a href="https://git-scm.org">Git</a> and <a href="https://git-annex.branchable.com">git-annex</a>. Its core data structure, DataLad datasets, can version control files of any size, and streamline data sharing, updating, and collaboration. In this hackathon project, we aim to make DataLad interoperable with Dataverse to support dataset transport from and to Dataverse instances. To this end, we will build a new DataLad extension <code class="language-plaintext highlighter-rouge">datalad-dataverse</code>, and would be delighted to welcome <strong>you</strong> onboard of the contributor team.</p> </p> <h5>SKILLS</h5> <p><p>We plan to start from zero with this project, and welcome all kinds of contributions from various skills at any level. From setting up and writing documentation, discussing relevant functionality, or user-experience-testing, to Python-based implementation of the desired functionality and creating real-world use cases and workflows. You can help us with any of the following skills: You have used a Dataverse instance before and/or have access to one, or you are interested in using one in the future - You know technical details about Dataverse, such as its API, or would have fun finding out about them - You know Python - You have experience with the Unix command line - You are interested in creating accessible documentation - You are interested in learning about the DataLad ecosystem or the process of creating a DataLad extension - Your secret hobby is Git plumbing - You know git-annex, and/or about its backends - You want to help create metadata extractors for Dataverse to generate dataset metadata automatically</p> </p> </div> </div> <div class="hackathon-row float-left col-md-12"> <div class="hackathon-img-wrapper animated hiding" data-animation="fadeInLeft" data-delay="0"> <img class="img-responsive" src="https://layerfmri.files.wordpress.com/2022/05/image-01.png" alt="Hackathon"> </div> <div class="hackathon-details animated hiding" data-animation="fadeInRight" data-delay="0"> <h4><a href="https://layerfmri.com/hackathon22/">MOSAIC for VASO fMRI</a></h4> <h6> Hubs: Europe / Middle East / Africa </h6> <h5>PROJECT DESCRIPTION</h5> <p><p>Vascular Space Occupancy is an fMRI method that is popular for high-resolution layer-fMRI. Currently, the most popular sequence is the one by Rüdiger Stirnberg from the DZNE in Bonn, which is actively being employed at more than 30 sites. This sequence concomitantly acquires fMRI BOLD and blood volume signals. In the SIEMENS reconstruction pipeline, these signals are mixed together within the same time series, which challenges its user friendliness. Specifically:</p> <ul> <li>The “raw” dicom2nii-converted time-series are not BIDS compatible (see <a href="https://github.com/bids-standard/bids-specification/issues/1001">https://github.com/bids-standard/bids-specification/issues/1001</a>).</li> <li>The order of odd and even BOLD and VASO image TRs is dependent on the nii-converter.</li> <li>Workarounds with 3D distortion correction, results in interpolation artifacts.</li> <li>Workarounds without MOSAIC decorators result in impracticable large data sizes.</li> </ul> <p>The goal of this Hackathon is to extend the 3D-MOSAIC to solve these constraints. This functor is commonly used to sort images by echo-times, by RF-channels, by magnitude and phase in the SIEMENS reconstruction pipeline into sets of mosaics . However currently, this functor does not yet support the dimensionality of SETs. In this project we seek to include SETs into the capabilities of the functor.</p> <p>Acknowledgements:</p> <p>This project is based on previous tests by Rüdiger Stirnberg and Philipp Ehses to isolate the cause of the problem. This project will be based on the mosaic functor that was originally developed by Ben Poser and is currently being further extended by Philipp Ehses. The compatibility of the “raw” data with BIDS are supported by BIDS extensions spear-headed by Remi Gau and supported by Daniel Handwerker. The Hackathon logistics across various internet platforms are kindly guided by our Hackathon mentor Faruk Gulban.</p> </p> <h5>SKILLS</h5> <p><ul> <li>SIEMENS ICE programming in VE</li> <li>C++</li> </ul> </p> </div> </div> <div class="hackathon-row float-left col-md-12"> <div class="hackathon-img-wrapper animated hiding" data-animation="fadeInLeft" data-delay="0"> <img class="img-responsive" src="https://neurocausal.github.io/images/author/inverted-logo_huf11703388d6cc09ec62cec26261f7e3e_54804_148x148_fit_box_2.png" alt="Hackathon"> </div> <div class="hackathon-details animated hiding" data-animation="fadeInRight" data-delay="0"> <h4><a href="https://github.com/neurocausal">NeuroCAUSAL - Development of an Open Source Platform for the Storage, Sharing, Synthesis and Meta-Analysis of Clinical Data</a></h4> <h6> Hubs: Americas, Europe / Middle East / Africa </h6> <h5>PROJECT DESCRIPTION</h5> <p><p>We wish to work with clinicians, neuroimagers, and software developers to develop an open source platform for the storage, sharing, synthesis and meta-analysis of human clinical data to the service of the clinical and cognitive neuroscience community so that the future of neuropsychology can be transdiagnostic, open, and FAIR.</p> <p>Following the steps of what enable similar transition in functional neuroimaging, we are breaking down the over-ambitious goal in two stages:</p> <ol> <li>Create a sort of spin-off of <a href="https://neuroquery.org/">Neuroquery</a> that only covers lesion-related data hence allowing causal inferences</li> <li>A <a href="https://neurovault.org/">Neurovault</a> kind of tool facilitating sharing of clinical data, which shall benefit from a sort of “neuropsyhcological BIDS formatting guidelines” (OHBM poster #2066 seems to have read our minds)</li> </ol> </p> <h5>SKILLS</h5> <p><p>We are very heterogeneous in our own skills sets &amp; levels and welcome all sorts of contributions 😄 <br /> The <strong>ontological issues</strong> we are facing require familiarity with <a href="https://github.com/neurocausal/neurocausal/issues/4">neurology</a> and/or <a href="https://github.com/neurocausal/neurocausal/issues/5">cognitive science</a>. These are contentious matters in the field and a perfect solution is not realistic: we seek the good compromise that will make this platform a useful tool for the broad community interested in the future of neuropsychology.<br /> The <strong>technical issues</strong> will benefit from people familiar with tools to scrap data from texts, train/test predictive models, generally speaking converting to code our pipeline of papers selection &gt; model fitting &gt; function-to-structure mapping visualization (<a href="https://github.com/neurocausal/neurocausal_data/issues/1">example</a>).<br /> We are aware we just started scratching the surface and will need lots of help on all fronts 🙏</p> </p> </div> </div> </div> </div> </section> <!-- End About Hackathon Section --> <!-- Begin Footer --> <footer id="footer" class="footer"> <div class="row"> <div class="pull-left col-md-6 col-xs-6"> <div class="g-plusone" data-size="medium" data-annotation="inline" data-width="300" data-href="https://ohbm.github.io/hackathon2022"></div> </div> <div class="logo logo-footer logo-gray pull-right"></div> </div> <div class="row"> <div class="col-md-4 col-xs-6"> <h5>Links</h5> <ul> <li><a href=" https://ossig.netlify.com/ " target="_blank">OHBM Open Science SIG</a></li> <li><a href=" https://www.brainhack.org/ " target="_blank">Brainhack Global</a></li> </ul> </div> <div class="col-md-4 col-xs-6"> <h5>Organizers and contacts</h5> <ul> <li><a href=" https://twitter.com/HaoTingW713 " target="_blank">Hao-Ting Wang (Brainhack Co-chair)</a></li> <li><a href=" https://twitter.com/SteMoia " target="_blank">Stefano Moia (Brainhack Co-chair)</a></li> <li><a href=" mailto:OHBMopenscience@gmail.com " target="_blank">OHBMopenscience@gmail.com</a></li> </ul> </div> <div class="col-md-4 col-xs-6"> <h5>Resources</h5> <ul> <li><a href=" /hackathon2022/coc " target="_blank">Code of Conduct</a></li> <li><a href=" /hackathon2022/contact/ " target="_blank">Contact</a></li> </ul> </div> </div> <div class="row"> <div class="col-md-6 col-xs-12"> <ul class="social-links"> <li> <a href=" https://twitter.com/ohbmopen " target="_blank"> <svg class="icon icon-twitter" viewBox="0 0 30 32"> <use xlink:href="/hackathon2022/img/sprites/sprites.svg#icon-twitter"></use> </svg> </a> </li> <li> <a href=" /hackathon2022/feed.xml " target="_blank"> <svg class="icon icon-rss" viewBox="0 0 30 32"> <use xlink:href="/hackathon2022/img/sprites/sprites.svg#icon-rss"></use> </svg> </a> </li> </ul> </div> </div> <div class="row"> <!-- Please don't delete this line--> <div class="col-md-6"> <p class="copyright"> &copy; 2018 Based on <a href="https://github.com/gdg-x/zeppelin" target="_blank">Project Zeppelin</a>. Designed and created by <a href="https://plus.google.com/+OlehZasadnyy/about" target="_blank">Oleh Zasadnyy</a> &middot; <br>Edited and re-adapted by Elizabeth Levitis and Remi Gau.</a> </p> </div> </div> </footer> <!-- End Footer --> </div> </div> </div> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', '', ''); ga('send', 'pageview'); </script> <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script> <script> window.jQuery || document.write('<script src="/hackathon2022/js/jquery-2.1.1.min.js><\/script>') </script> <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script> <script> if (typeof($.fn.modal) === 'undefined') { document.write('<script src="/hackathon2022/js/bootstrap.min.js><\/script>') } </script> <script src="/hackathon2022/js/default.js"></script> <script> Waves.displayEffect(); </script> <script src="/hackathon2022/js/scripts.js"></script> <script type="application/ld+json"> [{ "@context" : "http://schema.org", "@type" : "Event", "name" : "OHBM BrainHack 2022", "description": "OHBM Brainhack June 16-18th, 2022. Organized by the OHBM Open Science SIG.", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022", "url" : "https://ohbm.github.io/hackathon2022", "startDate" : "", "doorTime" : "", "endDate" : "", "location" : { "@type" : "Place", "name" : "", "sameAs" : "", "address" : { "@type" : "PostalAddress", "streetAddress" : "", "addressLocality" : "", "addressRegion" : "", "postalCode" : "", "addressCountry" : "" }, "geo" : { "@type" : "GeoCoordinates", "latitude" : "", "longitude" : "" } }, // Not supported yet // "organizer" : { // "@type" : "Organization", // "name" : "OHBM Open Science SIG", // "alternateName" : "", // "description" : "", // "logo" : "https://ohbm.github.io/hackathon2022/hackathon2022", // "email" : "", // "sameAs" : "" // }, "subEvent" : { "@type" : "Event", "name" : "HackTrack", "description": "", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022", "url" : "https://ohbm.github.io/hackathon2022/hackathon2022/hackathon/", "startDate" : "2022-06-16", "doorTime" : "09:00", "endDate" : "2022-06-16", "location" : { "@type" : "Place", "name" : "Queen Margaret Union", "sameAs" : "http://communa.net.ua/", "address" : { "@type" : "PostalAddress", "streetAddress" : "22 University Gardens", "addressLocality" : "Glasgow", "addressRegion" : "", "postalCode" : "G12 8QN", "addressCountry" : "United Kingdom" }, "geo" : { "@type" : "GeoCoordinates", "latitude" : "55.8735962", "longitude" : " -4.2913955" } } }, "offers" : [ { "@type" : "Offer", "name" : "Early Bird", "url" : "http://dfua.ticketforevent.com/", "price" : "350", "priceCurrency" : "UAH", "validFrom" : "2014-08-25T10:00", "validThrough" : "2014-09-30T23:59" } ], "performer" : [ { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" }, { "@type" : "Person", "name" : " ", "image" : "https://ohbm.github.io/hackathon2022/hackathon2022/img/people/", "jobTitle" : "", "worksFor" : { "@type" : "Organization", "name" : "" }, "sameAs" : "" } ], "eventStatus" : "EventScheduled", "typicalAgeRange" : "16+" }] </script> </body> </html>
